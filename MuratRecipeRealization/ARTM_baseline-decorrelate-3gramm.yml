# This config follows a strategy described by Murat Apishev
# one of the core programmers of BigARTM library in personal correspondence.
# According to his letter 'decent' topic model can be obtained by
# Decorrelating model topics simultaneously looking at retrieved TopTokens


# Use .format(modality_list=modality_list, main_modality=main_modality, dataset_path=dataset_path,
# specific_topics=specific_topics, background_topics=background_topics)
# when loading the recipe to adjust for your dataset

topics:
# Describes number of model topics, better left to the user to define optimal topic number
    specific_topics: {specific_topics} 
    background_topics: {background_topics}

# Here is example of model with one modality
regularizers:
    - DecorrelatorPhiRegularizer:
        name: decorrelation_phi_{modality1}
        topic_names: specific_topics
        class_ids: '{modality1}'
    - DecorrelatorPhiRegularizer:
        name: decorrelation_phi_{modality2}
        topic_names: specific_topics
        class_ids: '{modality2}'
    - DecorrelatorPhiRegularizer:
        name: decorrelation_phi_{modality3}
        topic_names: specific_topics
        class_ids: '{modality3}'
    - DecorrelatorPhiRegularizer:
        name: decorrelation_phi_{modality4}
        topic_names: specific_topics
        class_ids: '{modality4}'
    - SmoothSparsePhiRegularizer:
        name: smooth_phi_bcg
        topic_names: background_topics
        class_ids: {modality_list}
        tau: 0.1
        relative: true
    - SmoothSparseThetaRegularizer:
        name: smooth_theta_bcg
        topic_names: background_topics
        tau: 0.1
        relative: true
scores:
    - BleiLaffertyScore:
        num_top_tokens: 30
model: 
    dataset_path: {dataset_path}
    modalities_to_use: {modality_list}
    main_modality: '{main_modality}'

stages:
- RegularizersModifierCube:
    num_iter: 20
    reg_search: add
    regularizer_parameters:
        name: decorrelation_phi_{modality1}
    selection:
        - PerplexityScore{modality1} < 1.05 * MINIMUM(PerplexityScore{modality1}) and BleiLaffertyScore -> max
    strategy: PerplexityStrategy #{modality1}
    # parameters of this strategy are intended for revision
    strategy_params:
        start_point: 0
        step: 0.01
        max_len: 50
    tracked_score_function: PerplexityScore{modality1}
    verbose: false
    use_relative_coefficients: true
- RegularizersModifierCube:
    num_iter: 20
    reg_search: add
    regularizer_parameters:
        name: decorrelation_phi_{modality2}
    selection:
        - PerplexityScore{modality2} < 1.05 * MINIMUM(PerplexityScore{modality2}) and BleiLaffertyScore -> max
    strategy: PerplexityStrategy #{modality2}
    # parameters of this strategy are intended for revision
    strategy_params:
        start_point: 0
        step: 0.01
        max_len: 50
    tracked_score_function: PerplexityScore{modality2}
    verbose: false
    use_relative_coefficients: true
- RegularizersModifierCube:
    num_iter: 20
    reg_search: add
    regularizer_parameters:
        name: decorrelation_phi_{modality3}
    selection:
        - PerplexityScore{modality3} < 1.05 * MINIMUM(PerplexityScore{modality3}) and BleiLaffertyScore -> max
    strategy: PerplexityStrategy #{modality3}
    # parameters of this strategy are intended for revision
    strategy_params:
        start_point: 0
        step: 0.01
        max_len: 50
    tracked_score_function: PerplexityScore{modality3}
    verbose: false
    use_relative_coefficients: true
- RegularizersModifierCube:
    num_iter: 20
    reg_search: add
    regularizer_parameters:
        name: decorrelation_phi_{modality4}
    selection:
        - PerplexityScore{modality4} < 1.05 * MINIMUM(PerplexityScore{modality4}) and BleiLaffertyScore -> max
    strategy: PerplexityStrategy #{modality4}
    # parameters of this strategy are intended for revision
    strategy_params:
        start_point: 0
        step: 0.01
        max_len: 50
    tracked_score_function: PerplexityScore{modality4}
    verbose: false
    use_relative_coefficients: true
