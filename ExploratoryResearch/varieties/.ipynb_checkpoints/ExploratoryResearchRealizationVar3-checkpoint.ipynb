{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "import artm\n",
    "\n",
    "# change log style\n",
    "lc = artm.messages.ConfigureLoggingArgs()\n",
    "lc.minloglevel = 3\n",
    "lib = artm.wrapper.LibArtm(logging_config=lc)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    div.output_html {\n",
       "        white-space: nowrap;\n",
       "    }\n",
       "    div .output_subarea > pre {\n",
       "        white-space: pre;\n",
       "        word-wrap: normal;\n",
       "    }\n",
       "    div .output_stdout > pre {\n",
       "        white-space: pre-wrap !important;\n",
       "        word-wrap:  break-word !important;\n",
       "    }\n",
       "    </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from topicnet.cooking_machine.models.topic_model import TopicModel\n",
    "from topicnet.cooking_machine.cubes import RegularizersModifierCube\n",
    "from topicnet.cooking_machine.config_parser import build_experiment_environment_from_yaml_config\n",
    "from topicnet.cooking_machine.experiment import Experiment\n",
    "from topicnet.cooking_machine.cubes import *\n",
    "from topicnet.cooking_machine.dataset import Dataset\n",
    "from topicnet.cooking_machine.pretty_output import make_notebook_pretty\n",
    "make_notebook_pretty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import topicnet.cooking_machine.cubes as tncubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".container { width:90% !important; }\n",
       "div.output_scroll .output_subarea { white-space: pre; }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import clear_output, display_html\n",
    "display(HTML(\"\"\"<style>\n",
    ".container { width:90% !important; }\n",
    "div.output_scroll .output_subarea { white-space: pre; }\n",
    "</style>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# This config follows a strategy described in the article\n",
      "# Multi-objective Topic Modeling for Exploratory Search in Tech News\n",
      "# by Anastasya Yanina, Lev Golitsyn and Konstantin Vorontsov, Jan 2018\n",
      "\n",
      "\n",
      "# Use .format(modality=modality, dataset_path=dataset_path,\n",
      "# specific_topics=specific_topics, background_topics=background_topics)\n",
      "# when loading the recipe to adjust for your dataset\n",
      "\n",
      "topics:\n",
      "# Describes number of model topics, in the actuall article 200 topics were found to be optimal\n",
      "    specific_topics: ['topic_0', 'topic_1', 'topic_2', 'topic_3', 'topic_4', 'topic_5', 'topic_6', 'topic_7', 'topic_8', 'topic_9', 'topic_10', 'topic_11', 'topic_12', 'topic_13', 'topic_14', 'topic_15', 'topic_16', 'topic_17', 'topic_18', 'topic_19', 'topic_20', 'topic_21', 'topic_22', 'topic_23', 'topic_24', 'topic_25', 'topic_26', 'topic_27', 'topic_28', 'topic_29', 'topic_30', 'topic_31', 'topic_32', 'topic_33', 'topic_34']\n",
      "    background_topics: ['bcg_35']\n",
      "\n",
      "regularizers:\n",
      "- DecorrelatorPhiRegularizer:\n",
      "    name: decorrelation_phi_@word\n",
      "    topic_names: specific_topics\n",
      "    tau: 1\n",
      "    class_ids: ['@word']\n",
      "- SmoothSparseThetaRegularizer:\n",
      "    name: sparse_theta\n",
      "    topic_names: specific_topics\n",
      "    tau: 1\n",
      "- SmoothSparsePhiRegularizer:\n",
      "    name: smooth_phi_@word\n",
      "    topic_names: specific_topics\n",
      "    tau: 1\n",
      "    class_ids: ['@word']\n",
      "- DecorrelatorPhiRegularizer:\n",
      "    name: decorrelation_phi_@tag\n",
      "    topic_names: specific_topics\n",
      "    tau: 1\n",
      "    class_ids: ['@tag']\n",
      "- SmoothSparseThetaRegularizer:\n",
      "    name: sparse_theta\n",
      "    topic_names: specific_topics\n",
      "    tau: 1\n",
      "- SmoothSparsePhiRegularizer:\n",
      "    name: smooth_phi_@tag\n",
      "    topic_names: specific_topics\n",
      "    tau: 1\n",
      "    class_ids: ['@tag']\n",
      "\n",
      "model: \n",
      "    dataset_path: /home/sultan/datasets/PScience/PScience.csv\n",
      "    modalities_to_use: ['@word', '@tag']\n",
      "    main_modality: '@word'\n",
      "\n",
      "stages:\n",
      "# repeat the following two cubes for every modality in the dataset\n",
      "- RegularizersModifierCube:\n",
      "    num_iter: 8\n",
      "    reg_search: mul\n",
      "    regularizer_parameters:\n",
      "        name: decorrelation_phi_@word\n",
      "    selection:\n",
      "        - PerplexityScore@word < 1.01 * MINIMUM(PerplexityScore@word) and SparsityPhiScore@word -> max\n",
      "    strategy: PerplexityStrategy\n",
      "    strategy_params:\n",
      "        start_point: 100000\n",
      "        step: 10\n",
      "        max_len: 6\n",
      "    tracked_score_function: PerplexityScore@all\n",
      "    verbose: false\n",
      "    use_relative_coefficients: false\n",
      "- RegularizersModifierCube:\n",
      "    num_iter: 8\n",
      "    reg_search: add\n",
      "    regularizer_parameters:\n",
      "        name: sparse_theta\n",
      "    selection:\n",
      "        - PerplexityScore@all < 1.01 * MINIMUM(PerplexityScore@all) and SparsityPhiScore@word -> max\n",
      "    strategy: PerplexityStrategy\n",
      "    strategy_params:\n",
      "        start_point: -0.5\n",
      "        step: -0.5\n",
      "        max_len: 6\n",
      "    tracked_score_function: PerplexityScore@all\n",
      "    verbose: false\n",
      "    use_relative_coefficients: false\n",
      "- RegularizersModifierCube:\n",
      "    num_iter: 8\n",
      "    reg_search: add\n",
      "    regularizer_parameters:\n",
      "        name: smooth_phi_@word\n",
      "    selection:\n",
      "        - PerplexityScore@word < 1.01 * MINIMUM(PerplexityScore@word) and SparsityPhiScore@word -> max\n",
      "    strategy: PerplexityStrategy\n",
      "    strategy_params:\n",
      "        start_point: 0.25\n",
      "        step: 0.25\n",
      "        max_len: 6\n",
      "    tracked_score_function: PerplexityScore@word\n",
      "    verbose: false\n",
      "    use_relative_coefficients: false\n",
      "#last cube is independent of modalities and can be used only once\n",
      "\n",
      "- RegularizersModifierCube:\n",
      "    num_iter: 8\n",
      "    reg_search: mul\n",
      "    regularizer_parameters:\n",
      "        name: decorrelation_phi_@tag\n",
      "    selection:\n",
      "        - PerplexityScore@tag < 1.01 * MINIMUM(PerplexityScore@tag) and SparsityPhiScore@tag -> max\n",
      "    strategy: PerplexityStrategy\n",
      "    strategy_params:\n",
      "        start_point: 100000\n",
      "        step: 10\n",
      "        max_len: 6\n",
      "    tracked_score_function: PerplexityScore@all\n",
      "    verbose: false\n",
      "    use_relative_coefficients: false\n",
      "- RegularizersModifierCube:\n",
      "    num_iter: 8\n",
      "    reg_search: add\n",
      "    regularizer_parameters:\n",
      "        name: sparse_theta\n",
      "    selection:\n",
      "        - PerplexityScore@all < 1.01 * MINIMUM(PerplexityScore@all) and SparsityPhiScore@tag -> max\n",
      "    strategy: PerplexityStrategy\n",
      "    strategy_params:\n",
      "        start_point: -0.5\n",
      "        step: -0.5\n",
      "        max_len: 6\n",
      "    tracked_score_function: PerplexityScore@all\n",
      "    verbose: false\n",
      "    use_relative_coefficients: false\n",
      "- RegularizersModifierCube:\n",
      "    num_iter: 8\n",
      "    reg_search: add\n",
      "    regularizer_parameters:\n",
      "        name: smooth_phi_@tag\n",
      "    selection:\n",
      "        - PerplexityScore@tag < 1.01 * MINIMUM(PerplexityScore@tag) and SparsityPhiScore@tag -> max\n",
      "    strategy: PerplexityStrategy\n",
      "    strategy_params:\n",
      "        start_point: 0.25\n",
      "        step: 0.25\n",
      "        max_len: 6\n",
      "    tracked_score_function: PerplexityScore@tag\n",
      "    verbose: false\n",
      "    use_relative_coefficients: false\n",
      "#last cube is independent of modalities and can be used only once\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/sultan/recipes/exploratory_search-variant1.yml\", \"r\") as f:\n",
    "    yaml_string = f.read()\n",
    "\n",
    "DATASET_PATH = \"/home/sultan/datasets/PScience/PScience.csv\"\n",
    "specific_topics = [f'topic_{i}' for i in range(35)]\n",
    "background_topics = [f'bcg_{i}' for i in range(len(specific_topics),len(specific_topics) + 1)]\n",
    "\n",
    "yaml_string = yaml_string.format(\n",
    "    modality1='@word',\n",
    "    modality2='@tag',\n",
    "    dataset_path=DATASET_PATH,\n",
    "    specific_topics=specific_topics,\n",
    "    background_topics=background_topics)\n",
    "\n",
    "print(yaml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topicnet.cooking_machine.experiment import Experiment\n",
    "if os.path.exists(f'./ExploratoryResearchDemo') == True:\n",
    "    os.system(\"rm -rf ./ExploratoryResearchDemo\")\n",
    "experiment, dataset = build_experiment_environment_from_yaml_config(\n",
    "    yaml_string,\n",
    "    experiment_id='ExploratoryResearchDemo',\n",
    "    save_path='ExploratoryResearchDemo',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <generator object tqdm_notebook.__iter__ at 0x7fb270799308>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sultan/miniconda3/lib/python3.6/site-packages/tqdm/notebook.py\", line 227, in __iter__\n",
      "    self.sp(bar_style='danger')\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'sp'\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sultan/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sultan/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sultan/miniconda3/lib/python3.6/site-packages/topicnet/cooking_machine/cubes/base_cube.py\", line 218, in _train_models_and_report_results\n",
      "    returned_paths = self._train_models(experiment, topic_model, dataset, search_space)\n",
      "  File \"/home/sultan/miniconda3/lib/python3.6/site-packages/topicnet/cooking_machine/cubes/base_cube.py\", line 174, in _train_models\n",
      "    num_iterations=self.num_iter\n",
      "  File \"/home/sultan/miniconda3/lib/python3.6/site-packages/topicnet/cooking_machine/models/topic_model.py\", line 146, in _fit\n",
      "    num_collection_passes=1)\n",
      "  File \"/home/sultan/miniconda3/lib/python3.6/site-packages/artm/artm_model.py\", line 557, in fit_offline\n",
      "    batch_vectorizer.weights, 1, None, reset_nwt)),\n",
      "  File \"/home/sultan/miniconda3/lib/python3.6/site-packages/artm/artm_model.py\", line 99, in apply_async\n",
      "    return self._pool.apply_async(func, args) if self._pool else func(*args)\n",
      "  File \"/home/sultan/miniconda3/lib/python3.6/site-packages/artm/master_component.py\", line 841, in fit_offline\n",
      "    self._lib.ArtmFitOfflineMasterModel(self.master_id, args)\n",
      "  File \"/home/sultan/miniconda3/lib/python3.6/site-packages/artm/wrapper/api.py\", line 161, in artm_api_call\n",
      "    self._check_error(result)\n",
      "  File \"/home/sultan/miniconda3/lib/python3.6/site-packages/artm/wrapper/api.py\", line 97, in _check_error\n",
      "    raise exception_class(error_message)\n",
      "artm.wrapper.exceptions.InvalidOperationException: TopicKernelScoreConfig.class_id @tag does not exists in n_wt matrix\n"
     ]
    },
    {
     "ename": "Empty",
     "evalue": "Failed to retrive number of trained models",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-85f17b779c17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/topicnet/cooking_machine/experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, dataset, verbose, nb_verbose)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0mcube\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcube_description\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cube'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m             \u001b[0mcube\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;31m# TODO: either delete this line completely\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/topicnet/cooking_machine/cubes/base_cube.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, topic_model_input, dataset)\u001b[0m\n\u001b[1;32m    335\u001b[0m             ]\n\u001b[1;32m    336\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_cube\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_model_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/topicnet/cooking_machine/cubes/base_cube.py\u001b[0m in \u001b[0;36m_run_cube\u001b[0;34m(self, topic_model, dataset)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mtopic_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve_results_from_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mreturned_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/topicnet/cooking_machine/cubes/base_cube.py\u001b[0m in \u001b[0;36m_retrieve_results_from_process\u001b[0;34m(self, queue, experiment)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_retrieve_results_from_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDummyTopicModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mmodels_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_from_queue_till_fail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_MODELS_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0mtopic_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/topicnet/cooking_machine/cubes/base_cube.py\u001b[0m in \u001b[0;36mget_from_queue_till_fail\u001b[0;34m(queue, error_message, fail_margin)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mfail_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: Failed to retrive number of trained models"
     ]
    }
   ],
   "source": [
    "experiment.run(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = experiment.select(experiment.criteria[-1][0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tms = experiment.models\n",
    "colors = np.linspace(0, 0.65, len(tms))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for i, tm in enumerate(list(tms.values())[1:]):\n",
    "    score = tm.scores['PerplexityScore@all']\n",
    "    plt.plot(score[1:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "tms = experiment.models\n",
    "colors = np.linspace(0, 0.65, len(tms))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for i, tm in enumerate(list(tms.values())[1:]):\n",
    "    score = tm.scores['TopicKernel@word.average_purity']\n",
    "    plt.plot(score, color=cm.Blues(colors[i]))\n",
    "    score = tm.scores['TopicKernel@word.average_contrast']\n",
    "    plt.plot(score, color=cm.Reds(colors[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    \"TopicKernel@word.average_contrast > 0.8 * MAXIMUM(TopicKernel@word.average_contrast) \"\n",
    "    \"and TopicKernel@word.average_purity > 0.8 * MAXIMUM(TopicKernel@word.average_purity) \"\n",
    "    \"and PerplexityScore@all < 1.1 * MINIMUM(PerplexityScore@all) \"\n",
    ")\n",
    "models = experiment.select(query + \" COLLECT all\")\n",
    "def describe_model(model):\n",
    "    for reg_name, reg in model.regularizers._data.items():\n",
    "        print(reg_name, reg.tau)\n",
    "    print(model.scores[\"PerplexityScore@all\"][-1])\n",
    "    print(model.scores[\"TopicKernel@word.average_contrast\"][-1])\n",
    "    print(model.scores[\"TopicKernel@word.average_purity\"][-1])\n",
    "    print(\"------\")\n",
    "for model in models:\n",
    "    describe_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topicnet.viewers.top_tokens_viewer import TopTokensViewer\n",
    "from topicnet.viewers.top_documents_viewer import TopDocumentsViewer\n",
    "from IPython.display import display_html, display\n",
    "from topicnet.cooking_machine.dataset import get_modality_vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 1e-5\n",
    "demo_data = Dataset(DATASET_PATH)\n",
    "first_model_top_tok = TopTokensViewer(best_model, num_top_tokens=10, method='phi')\n",
    "first_model_html =  first_model_top_tok.to_html(first_model_top_tok.view(),thresh=thresh)\n",
    "first_model_top_doc = TopDocumentsViewer(best_model, dataset=demo_data).view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n=7\n",
    "for line, topic_docs in list(zip(first_model_html, first_model_top_doc))[-n:]:\n",
    "    display_html(line, raw=True)\n",
    "    for doc_id in topic_docs:\n",
    "        doc_vw = demo_data.get_vw_document(doc_id).values[0][0]\n",
    "        doc_title = get_modality_vw(doc_vw, \"@title\")\n",
    "        doc_snippet = get_modality_vw(doc_vw, \"@snippet\")\n",
    "        display_html(f\"<b>{doc_title}</b>\", raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topicnet.viewers import TopSimilarDocumentsViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdv = TopSimilarDocumentsViewer(best_model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get_source_document(search_doc)['raw_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_doc = '174.txt'\n",
    "sim_docs, scores = tsdv.view(\n",
    "    search_doc,\n",
    "    metric='euclidean',\n",
    "    num_top_similar=10)\n",
    "for doc_id in sim_docs:\n",
    "    document = dataset.get_source_document(doc_id)\n",
    "    doc_title = document.index.values[0]\n",
    "    doc_snippet = '.'.join(document['raw_text'].values[0].split('.')[:3])\n",
    "    display_html(f\"<b>{doc_title}</b><br />{doc_snippet}\", raw=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
